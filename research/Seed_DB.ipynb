{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pke\n",
    "import json\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "import os\n",
    "import pickle\n",
    "from typing import List\n",
    "from SentenceGraph.core import SentenceGraph, Format, TextNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePickle(data, save_path) -> None:\n",
    "    try:\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error: {e} with trying to save pickle at: {save_path}\")\n",
    "\n",
    "\n",
    "def loadPickle(load_path) -> None:\n",
    "    try:\n",
    "        with open(load_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error: {e} with trying to load pickle at: {load_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts = []\n",
    "root_path = \"./data/sample\"\n",
    "sample_data = [\"weather_CO2.jsonl\", \"paleoclimate.jsonl\", \"rewilding.jsonl\", \"rockfish.jsonl\", \"arctic.jsonl\", \"climate.jsonl\", \"shark_climate.jsonl\"]\n",
    "\n",
    "for data_path in sample_data:\n",
    "    with open(f'{root_path}/{data_path}', 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "\n",
    "    result = json.loads(json_list[0])\n",
    "\n",
    "    for result_dict in result[\"data\"]:\n",
    "        abstracts.append(result_dict)\n",
    "\n",
    "len(abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [y for y in (x for x in abstracts) if y[\"abstract\"] is not None]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:12<00:00,  1.75s/it]\n",
      "2022-12-17 23:22:08,358 - BERTopic - Transformed documents to Embeddings\n",
      "2022-12-17 23:22:09,951 - BERTopic - Reduced dimensionality\n",
      "2022-12-17 23:22:09,970 - BERTopic - Clustered reduced embeddings\n"
     ]
    }
   ],
   "source": [
    "# we add this to remove stopwords\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
    "\n",
    "model = BERTopic(\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    language='english', calculate_probabilities=True,\n",
    "    verbose=True\n",
    ")\n",
    "topics, probs = model.fit_transform([x['abstract'] for x in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize keyphrase extraction model, here TopicRank\n",
    "extractor = pke.unsupervised.TopicRank()\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_ent_dict = {}\n",
    "# This loop is the main processing loop\n",
    "for item, topicId in zip(data, topics):\n",
    "    topicNormalized = '_'.join([x[0] for x in model.get_topic(topicId)])\n",
    "    item['topic'] = topicNormalized\n",
    "\n",
    "    abstract = item['abstract']\n",
    "    entities = []\n",
    "\n",
    "    if abstract is None:\n",
    "        print(\"Found a none!\")\n",
    "    else:\n",
    "        # Extract entities\n",
    "        extractor.load_document(input=abstract, language='en')\n",
    "        extractor.candidate_selection()\n",
    "        extractor.candidate_weighting()\n",
    "        ents_keep = [x[0].lower() for x in extractor.get_n_best(n=2)]\n",
    "        item['ents'] = ents_keep\n",
    "\n",
    "        try:\n",
    "            topic_ent_dict[topicNormalized].extend(ents_keep)\n",
    "        except KeyError:\n",
    "            topic_ent_dict[topicNormalized] = ents_keep\n",
    "\n",
    "        # Tokenize sentences\n",
    "        doc = nlp(item['abstract'])\n",
    "        # spaCy returns a generator, so use a list comprehension to make our lives easier \n",
    "        item['sentences'] = [sent.text for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "savePickle(topic_ent_dict, './data/topic_ent_dict_checkpoint.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_labels = topic_ent_dict.keys()\n",
    "for topic in entity_labels:\n",
    "    topic_ent_dict[topic] = list(set(topic_ent_dict[topic]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "driver = GraphDatabase.driver(uri, auth=(\"neo4j\", \"hackathon\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cypher "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Creation queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paper_node(tx, paperId: str, title: str, abstract: str) -> None:\n",
    "    tx.run(\"CREATE (a:Paper {paperId: $paperId, title: $title, abstract: $abstract})\", paperId=paperId, title=title, abstract=abstract)\n",
    "\n",
    "def create_keyword_node(tx, entity_name: str, label_name: str) -> None:\n",
    "    tx.run(\"CREATE (a:Keyword {entity_name: $entity_name, label_name: $label_name})\", entity_name=entity_name, label_name=label_name)\n",
    "\n",
    "def create_topic_node(tx, topic_name: str) -> None:\n",
    "    tx.run(\"CREATE (a:Topic {topic_name: $topic_name})\", topic_name=topic_name)\n",
    "    \n",
    "def create_sentence_node(tx, paperId: str, sentence_id: str, sentence_txt: str) -> None:\n",
    "    tx.run(\"CREATE (s:Sentence {paperId: $paperId, sentence_id: $sentence_id, sentence_txt: $sentence_txt})\", paperId=paperId, sentence_id=sentence_id, sentence_txt=sentence_txt)\n",
    "\n",
    "def create_author_node(tx, authorId: str, author_name: str) -> None:\n",
    "    tx.run(\"CREATE (a:Author {authorId: $authorId, author_name: $author_name})\", authorId=authorId, author_name=author_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword Relationships\n",
    "\n",
    "TODO: Lets start switching over to using Keyword instead of Entity. More user friendly imo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paper_has_keyword_relationship(tx, paperId, entity_name):\n",
    "    tx.run(\"MATCH (kw:Keyword) WHERE kw.entity_name = $entity_name \"\n",
    "            \"MATCH (paper:Paper) WHERE paper.paperId = $paperId \"\n",
    "            \"CREATE (paper)-[:HAS_KEYWORD]->(kw)\",\n",
    "           entity_name=entity_name, paperId=paperId)\n",
    "\n",
    "def create_keyword_in_paper_relationship(tx, paperId, entity_name):\n",
    "    tx.run(\"MATCH (kw:Keyword) WHERE kw.entity_name = $entity_name \"\n",
    "            \"MATCH (paper:Paper) WHERE paper.paperId = $paperId \"\n",
    "            \"CREATE (kw)-[:IN_PAPER]->(paper)\",\n",
    "           entity_name=entity_name, paperId=paperId)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paper_in_topic_relationship(tx, paperId, topic_name):\n",
    "    tx.run(\"MATCH (topic:Topic) WHERE topic.topic_name = $topic_name \"\n",
    "            \"MATCH (paper:Paper) WHERE paper.paperId = $paperId \"\n",
    "            \"CREATE (paper)-[:IN_TOPIC]->(topic)\",\n",
    "           topic_name=topic_name, paperId=paperId)\n",
    "\n",
    "def create_topic_has_paper_relationship(tx, paperId, topic_name):\n",
    "    tx.run(\"MATCH (topic:Topic) WHERE topic.topic_name = $topic_name \"\n",
    "            \"MATCH (paper:Paper) WHERE paper.paperId = $paperId \"\n",
    "            \"CREATE (topic)-[:HAS_PAPER]->(paper)\",\n",
    "           topic_name=topic_name, paperId=paperId)\n",
    "\n",
    "def create_keyword_in_topic_relationship(tx, entity_name, topic_name):\n",
    "    tx.run(\"MATCH (topic:Topic) WHERE topic.topic_name = $topic_name \"\n",
    "            \"MATCH (kw:Keyword) WHERE kw.entity_name = $entity_name \"\n",
    "            \"CREATE (kw)-[:IN_TOPIC]->(topic)\",\n",
    "           topic_name=topic_name, entity_name=entity_name)\n",
    "\n",
    "def create_topic_has_keyword_relationship(tx, entity_name, topic_name):\n",
    "    tx.run(\"MATCH (topic:Topic) WHERE topic.topic_name = $topic_name \"\n",
    "            \"MATCH (kw:Keyword) WHERE kw.entity_name = $entity_name \"\n",
    "            \"CREATE (topic)-[:HAS_KEYWORD]->(kw)\",\n",
    "           topic_name=topic_name, entity_name=entity_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paper_has_sentence_relationship(tx, sentence_id, paperId):\n",
    "    tx.run(\"MATCH (s:Sentence) WHERE s.sentence_id = $sentence_id \"\n",
    "            \"MATCH (p:Paper) WHERE p.paperId = $paperId \"\n",
    "            \"CREATE (p)-[:HAS_SENTENCE]->(s)\",\n",
    "           sentence_id=sentence_id, paperId=paperId)\n",
    "\n",
    "def create_sentence_in_paper_relationship(tx, sentence_id, paperId):\n",
    "    tx.run(\"MATCH (s:Sentence) WHERE s.sentence_id = $sentence_id \"\n",
    "            \"MATCH (p:Paper) WHERE p.paperId = $paperId \"\n",
    "            \"CREATE (s)-[:IN_PAPER]->(p)\",\n",
    "           sentence_id=sentence_id, paperId=paperId)\n",
    "\n",
    "def create_semantic_sentence_relationship(tx, sentence_id1, sentence_id2, score):\n",
    "    tx.run(\"MATCH (s1:Sentence) WHERE s1.sentence_id = $sentence_id1 \"\n",
    "            \"MATCH (s2:Sentence) WHERE s2.sentence_id = $sentence_id2 \"\n",
    "            \"CREATE (s1)-[:SIMILAR {score: $score}]->(s2)\",\n",
    "           sentence_id1=sentence_id1, sentence_id2=sentence_id2, score=score)\n",
    "\n",
    "def create_keyword_in_sentence_relationship(tx, entity_name, sentence_id):\n",
    "    tx.run(\"MATCH (sent:Sentence) WHERE s.sentence_id = $sentence_id \"\n",
    "            \"MATCH (kw:Keyword) WHERE kw.entity_name = $entity_name \"\n",
    "            \"CREATE (kw)-[:IN_SENTENCE]->(sent)\",\n",
    "           sentence_id=sentence_id, entity_name=entity_name)\n",
    "\n",
    "def create_sentence_has_keyword_relationship(tx, entity_name, sentence_id):\n",
    "    tx.run(\"MATCH (sent:Sentence) WHERE s.sentence_id = $sentence_id \"\n",
    "            \"MATCH (kw:Keyword) WHERE kw.entity_name = $entity_name \"\n",
    "            \"CREATE (sent)-[:HAS_KEYWORD]->(kw)\",\n",
    "           sentence_id=sentence_id, entity_name=entity_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_authored_relationship(tx, paperId, authorId):\n",
    "    tx.run(\"MATCH (a:Author) WHERE a.authorId = $authorId \"\n",
    "            \"MATCH (b:Paper) WHERE b.paperId = $paperId \"\n",
    "            \"CREATE (a)-[:AUTHORED]->(b)\"\n",
    "            \"CREATE (b)-[:AUTHORED]->(a)\",\n",
    "           authorId=authorId, paperId=paperId)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populating the graph (from scratch)\n",
    "Run this code only during local development or if youre recreating a graph from scratch. Not meant to touch the production graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transaction failed and will be retried in 0.9465203664762873s (Couldn't connect to localhost:7687 (resolved to ()):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] No connection could be made because the target machine actively refused it))\n",
      "Transaction failed and will be retried in 1.9095661851587753s (Couldn't connect to localhost:7687 (resolved to ()):\n",
      "Failed to establish connection to ResolvedIPv6Address(('::1', 7687, 0, 0)) (reason [WinError 10061] No connection could be made because the target machine actively refused it)\n",
      "Failed to establish connection to ResolvedIPv4Address(('127.0.0.1', 7687)) (reason [WinError 10061] No connection could be made because the target machine actively refused it))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\anthonyhevia\\Desktop\\code\\ClimateScholar\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py:504\u001b[0m, in \u001b[0;36mBoltSocket._connect\u001b[1;34m(cls, resolved_address, timeout, keep_alive)\u001b[0m\n\u001b[0;32m    503\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39m[#0000]  C: <OPEN> \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, resolved_address)\n\u001b[1;32m--> 504\u001b[0m s\u001b[39m.\u001b[39;49mconnect(resolved_address)\n\u001b[0;32m    505\u001b[0m s\u001b[39m.\u001b[39msettimeout(t)\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [39], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mwith\u001b[39;00m driver\u001b[39m.\u001b[39msession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m      9\u001b[0m     \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m data:\n\u001b[0;32m     10\u001b[0m         \u001b[39m# Create the core paper node\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m         session\u001b[39m.\u001b[39;49mexecute_write(create_paper_node, item[\u001b[39m'\u001b[39;49m\u001b[39mpaperId\u001b[39;49m\u001b[39m'\u001b[39;49m], item[\u001b[39m'\u001b[39;49m\u001b[39mtitle\u001b[39;49m\u001b[39m'\u001b[39;49m], item[\u001b[39m'\u001b[39;49m\u001b[39mabstract\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     13\u001b[0m         \u001b[39mif\u001b[39;00m item[\u001b[39m'\u001b[39m\u001b[39mtopic\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m seen_topics:\n\u001b[0;32m     14\u001b[0m             seen_topics\u001b[39m.\u001b[39madd(item[\u001b[39m'\u001b[39m\u001b[39mtopic\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\anthonyhevia\\Desktop\\code\\ClimateScholar\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py:702\u001b[0m, in \u001b[0;36mSession.execute_write\u001b[1;34m(self, transaction_function, *args, **kwargs)\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexecute_write\u001b[39m(\n\u001b[0;32m    659\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    660\u001b[0m     transaction_function: t\u001b[39m.\u001b[39mCallable[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    663\u001b[0m     \u001b[39m*\u001b[39margs: _P\u001b[39m.\u001b[39margs,  \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: _P\u001b[39m.\u001b[39mkwargs\n\u001b[0;32m    664\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m _R:\n\u001b[0;32m    665\u001b[0m     \u001b[39m\"\"\"Execute a unit of work in a managed write transaction.\u001b[39;00m\n\u001b[0;32m    666\u001b[0m \n\u001b[0;32m    667\u001b[0m \u001b[39m    .. note::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[39m    .. versionadded:: 5.0\u001b[39;00m\n\u001b[0;32m    701\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 702\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_transaction(\n\u001b[0;32m    703\u001b[0m         WRITE_ACCESS, transaction_function, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    704\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\anthonyhevia\\Desktop\\code\\ClimateScholar\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py:474\u001b[0m, in \u001b[0;36mSession._run_transaction\u001b[1;34m(self, access_mode, transaction_function, *args, **kwargs)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    473\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 474\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open_transaction(\n\u001b[0;32m    475\u001b[0m             tx_cls\u001b[39m=\u001b[39;49mManagedTransaction,\n\u001b[0;32m    476\u001b[0m             access_mode\u001b[39m=\u001b[39;49maccess_mode, metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[0;32m    477\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    478\u001b[0m         )\n\u001b[0;32m    479\u001b[0m         tx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transaction\n\u001b[0;32m    480\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\anthonyhevia\\Desktop\\code\\ClimateScholar\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py:391\u001b[0m, in \u001b[0;36mSession._open_transaction\u001b[1;34m(self, tx_cls, access_mode, metadata, timeout)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_transaction\u001b[39m(\n\u001b[0;32m    389\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, tx_cls, access_mode, metadata\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    390\u001b[0m ):\n\u001b[1;32m--> 391\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_connect(access_mode\u001b[39m=\u001b[39;49maccess_mode)\n\u001b[0;32m    392\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transaction \u001b[39m=\u001b[39m tx_cls(\n\u001b[0;32m    393\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mfetch_size,\n\u001b[0;32m    394\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transaction_closed_handler,\n\u001b[0;32m    395\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transaction_error_handler,\n\u001b[0;32m    396\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transaction_cancel_handler\n\u001b[0;32m    397\u001b[0m     )\n\u001b[0;32m    398\u001b[0m     bookmarks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_all_bookmarks()\n",
      "File \u001b[1;32mc:\\Users\\anthonyhevia\\Desktop\\code\\ClimateScholar\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\session.py:121\u001b[0m, in \u001b[0;36mSession._connect\u001b[1;34m(self, access_mode, **access_kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     access_mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mdefault_access_mode\n\u001b[0;32m    120\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 121\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_connect(access_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49maccess_kwargs)\n\u001b[0;32m    122\u001b[0m \u001b[39mexcept\u001b[39;00m asyncio\u001b[39m.\u001b[39mCancelledError:\n\u001b[0;32m    123\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_cancellation(message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_connect\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\anthonyhevia\\Desktop\\code\\ClimateScholar\\venv\\lib\\site-packages\\neo4j\\_sync\\work\\workspace.py:194\u001b[0m, in \u001b[0;36mWorkspace._connect\u001b[1;34m(self, access_mode, **acquire_kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m acquire_kwargs_ \u001b[39m=\u001b[39m {\n\u001b[0;32m    187\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maccess_mode\u001b[39m\u001b[39m\"\u001b[39m: access_mode,\n\u001b[0;32m    188\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: acquisition_timeout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mliveness_check_timeout\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    192\u001b[0m }\n\u001b[0;32m    193\u001b[0m acquire_kwargs_\u001b[39m.\u001b[39mupdate(acquire_kwargs)\n\u001b[1;32m--> 194\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pool\u001b[39m.\u001b[39;49macquire(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49macquire_kwargs_)\n\u001b[0;32m    195\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_connection_access_mode \u001b[39m=\u001b[39m access_mode\n",
      "File \u001b[1;32mc:\\Users\\anthonyhevia\\Desktop\\code\\ClimateScholar\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:400\u001b[0m, in \u001b[0;36mBoltPool.acquire\u001b[1;34m(self, access_mode, timeout, database, bookmarks, liveness_check_timeout)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39macquire\u001b[39m(\n\u001b[0;32m    395\u001b[0m     \u001b[39mself\u001b[39m, access_mode, timeout, database, bookmarks, liveness_check_timeout\n\u001b[0;32m    396\u001b[0m ):\n\u001b[0;32m    397\u001b[0m     \u001b[39m# The access_mode and database is not needed for a direct connection,\u001b[39;00m\n\u001b[0;32m    398\u001b[0m     \u001b[39m# it's just there for consistency.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m     deadline \u001b[39m=\u001b[39m Deadline\u001b[39m.\u001b[39mfrom_timeout_or_deadline(timeout)\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_acquire(\n\u001b[0;32m    401\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maddress, deadline, liveness_check_timeout\n\u001b[0;32m    402\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\anthonyhevia\\Desktop\\code\\ClimateScholar\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:216\u001b[0m, in \u001b[0;36mIOPool._acquire\u001b[1;34m(self, address, deadline, liveness_check_timeout)\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    209\u001b[0m             timeout \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# deadline expired\u001b[39;00m\n\u001b[0;32m    210\u001b[0m             \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcond\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    211\u001b[0m         ):\n\u001b[0;32m    212\u001b[0m             \u001b[39mraise\u001b[39;00m ClientError(\n\u001b[0;32m    213\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfailed to obtain a connection from the pool within \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39ms (timeout)\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(deadline\u001b[39m.\u001b[39moriginal_timeout)\n\u001b[0;32m    215\u001b[0m             )\n\u001b[1;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m connection_creator()\n",
      "File \u001b[1;32mc:\\Users\\anthonyhevia\\Desktop\\code\\ClimateScholar\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:138\u001b[0m, in \u001b[0;36mIOPool._acquire_new_later.<locals>.connection_creator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 138\u001b[0m         connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mopener(\n\u001b[0;32m    139\u001b[0m             address, deadline\u001b[39m.\u001b[39;49mto_timeout()\n\u001b[0;32m    140\u001b[0m         )\n\u001b[0;32m    141\u001b[0m     \u001b[39mexcept\u001b[39;00m ServiceUnavailable:\n\u001b[0;32m    142\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeactivate(address)\n",
      "File \u001b[1;32mc:\\Users\\anthonyhevia\\Desktop\\code\\ClimateScholar\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_pool.py:378\u001b[0m, in \u001b[0;36mBoltPool.open.<locals>.opener\u001b[1;34m(addr, timeout)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopener\u001b[39m(addr, timeout):\n\u001b[1;32m--> 378\u001b[0m     \u001b[39mreturn\u001b[39;00m Bolt\u001b[39m.\u001b[39;49mopen(\n\u001b[0;32m    379\u001b[0m         addr, auth\u001b[39m=\u001b[39;49mauth, timeout\u001b[39m=\u001b[39;49mtimeout, routing_context\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    380\u001b[0m         pool_config\u001b[39m=\u001b[39;49mpool_config\n\u001b[0;32m    381\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\anthonyhevia\\Desktop\\code\\ClimateScholar\\venv\\lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py:319\u001b[0m, in \u001b[0;36mBolt.open\u001b[1;34m(cls, address, auth, timeout, routing_context, pool_config)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39melif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     socket_connection_timeout \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(pool_config\u001b[39m.\u001b[39mconnection_timeout,\n\u001b[0;32m    317\u001b[0m                                     time_remaining())\n\u001b[0;32m    318\u001b[0m s, pool_config\u001b[39m.\u001b[39mprotocol_version, handshake, data \u001b[39m=\u001b[39m \\\n\u001b[1;32m--> 319\u001b[0m     BoltSocket\u001b[39m.\u001b[39;49mconnect(\n\u001b[0;32m    320\u001b[0m         address,\n\u001b[0;32m    321\u001b[0m         timeout\u001b[39m=\u001b[39;49msocket_connection_timeout,\n\u001b[0;32m    322\u001b[0m         custom_resolver\u001b[39m=\u001b[39;49mpool_config\u001b[39m.\u001b[39;49mresolver,\n\u001b[0;32m    323\u001b[0m         ssl_context\u001b[39m=\u001b[39;49mpool_config\u001b[39m.\u001b[39;49mget_ssl_context(),\n\u001b[0;32m    324\u001b[0m         keep_alive\u001b[39m=\u001b[39;49mpool_config\u001b[39m.\u001b[39;49mkeep_alive,\n\u001b[0;32m    325\u001b[0m     )\n\u001b[0;32m    327\u001b[0m \u001b[39m# Carry out Bolt subclass imports locally to avoid circular dependency\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[39m# issues.\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m pool_config\u001b[39m.\u001b[39mprotocol_version \u001b[39m==\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m0\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\anthonyhevia\\Desktop\\code\\ClimateScholar\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py:646\u001b[0m, in \u001b[0;36mBoltSocket.connect\u001b[1;34m(cls, address, timeout, custom_resolver, ssl_context, keep_alive)\u001b[0m\n\u001b[0;32m    644\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    645\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 646\u001b[0m     s \u001b[39m=\u001b[39m BoltSocket\u001b[39m.\u001b[39;49m_connect(resolved_address, timeout, keep_alive)\n\u001b[0;32m    647\u001b[0m     s \u001b[39m=\u001b[39m BoltSocket\u001b[39m.\u001b[39m_secure(s, resolved_address\u001b[39m.\u001b[39mhost_name,\n\u001b[0;32m    648\u001b[0m                            ssl_context)\n\u001b[0;32m    649\u001b[0m     \u001b[39mreturn\u001b[39;00m BoltSocket\u001b[39m.\u001b[39m_handshake(s, resolved_address)\n",
      "File \u001b[1;32mc:\\Users\\anthonyhevia\\Desktop\\code\\ClimateScholar\\venv\\lib\\site-packages\\neo4j\\_async_compat\\network\\_bolt_socket.py:504\u001b[0m, in \u001b[0;36mBoltSocket._connect\u001b[1;34m(cls, resolved_address, timeout, keep_alive)\u001b[0m\n\u001b[0;32m    502\u001b[0m     s\u001b[39m.\u001b[39msettimeout(timeout)\n\u001b[0;32m    503\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39m[#0000]  C: <OPEN> \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, resolved_address)\n\u001b[1;32m--> 504\u001b[0m s\u001b[39m.\u001b[39;49mconnect(resolved_address)\n\u001b[0;32m    505\u001b[0m s\u001b[39m.\u001b[39msettimeout(t)\n\u001b[0;32m    506\u001b[0m keep_alive \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m keep_alive \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seen_authors = set()\n",
    "seen_keywords = set()\n",
    "seen_topics = set()\n",
    "\n",
    "def get_sentence_id(paperId: str, count: int) -> str:\n",
    "    f\"{paperId}-{count}\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    for item in data:\n",
    "        # Create the core paper node\n",
    "        session.execute_write(create_paper_node, item['paperId'], item['title'], item['abstract'])\n",
    "\n",
    "        if item['topic'] not in seen_topics:\n",
    "            seen_topics.add(item['topic'])\n",
    "            session.execute_write(create_topic_node, item['topic'])\n",
    "        \n",
    "        session.execute_write(create_paper_in_topic_relationship, item['paperId'], item['topic'])\n",
    "        session.execute_write(create_topic_has_paper_relationship, item['paperId'], item['topic'])\n",
    "\n",
    "        # Create the entity nodes\n",
    "        for ent in item['ents']:\n",
    "            if ent not in seen_keywords:\n",
    "                seen_keywords.add(ent)\n",
    "                label_name = f\"{item['topic']}\"\n",
    "                session.execute_write(create_keyword_node, ent, label_name)\n",
    "                session.execute_write(create_keyword_in_topic_relationship, ent, item['topic'])\n",
    "                session.execute_write(create_topic_has_keyword_relationship, ent, item['topic'])\n",
    "\n",
    "            session.execute_write(create_paper_has_keyword_relationship, item['paperId'], ent)\n",
    "            session.execute_write(create_keyword_in_paper_relationship, item['paperId'], ent)\n",
    "\n",
    "        # Create the author nodes and relationships\n",
    "        for author in item['authors']:\n",
    "            if author['authorId'] not in seen_authors:\n",
    "                seen_authors.add(author['authorId'])\n",
    "                session.execute_write(create_author_node, author['authorId'], author['name'])\n",
    "\n",
    "            session.execute_write(create_authored_relationship, item['paperId'], author['authorId'])\n",
    "\n",
    "        for count, sentence in enumerate(item['sentences']):\n",
    "            sentence_id = get_sentence_id(item['paperId'], count)\n",
    "            session.execute_write(create_sentence_node, item['paperId'], sentence_id, sentence)\n",
    "            session.execute_write(create_paper_has_sentence_relationship, sentence_id, item['paperId'])\n",
    "            session.execute_write(create_sentence_in_paper_relationship, sentence_id, item['paperId'])\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Sentence-Keyword relationships\n",
    "After we populate the graph with all the keywords, we can create any keyword/sentence relationships to enrich the graph with more granular mappings of where keywords might be located in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    for item in data:\n",
    "        for count, sentence in enumerate(item['sentences']):\n",
    "            sentence_id = get_sentence_id(item['paperId'], count)\n",
    "            for keyword in seen_keywords:\n",
    "                # We lowercased the keywords when we first created the list, so no need to do so now. \n",
    "                if keyword in sentence.lower():\n",
    "                    session.execute_write(create_keyword_in_sentence_relationship, keyword, sentence_id)\n",
    "                    session.execute_write(create_sentence_has_keyword_relationship, keyword, sentence_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the semantic  graph\n",
    "Using the SentenceGraph package (ðŸ˜‰) we can also create a similarity matrix between all the paper abstracts.\n",
    "\n",
    "TODO: This was originally planned with sentence similarity in mind, but we should measure the compute cost with that since thats a huge number more edge connections as opposed to computing all the similarities between abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_nodes = []\n",
    "\n",
    "for item in data:\n",
    "    if item['abstract'] is None:\n",
    "        pass\n",
    "    else:\n",
    "        paper_nodes.append(TextNode(item['paperId'], item['abstract']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceGraph = SentenceGraph(model_name=\"gsarti/scibert-nli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_graph = sentenceGraph.createGraph(paper_nodes, format=Format.Pandas)\n",
    "sim_graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "745c367861b30f1c58cafb364187217d1090c2a4237d47b4ad449d5ad8917489"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
